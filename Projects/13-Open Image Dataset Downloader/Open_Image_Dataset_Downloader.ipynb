{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrT5jiElk4DU"
      },
      "source": [
        "#Download dataset (images and labels) from Open Image Dataset V7 , YOLOv8 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tNPA5EkaHLK8",
        "outputId": "93a5b819-465e-4254-e806-c6f002a3b8ac"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/NanoCode012/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dAcPZWoxHQAZ",
        "outputId": "11117454-f505-4609-b3b8-492453abc366"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zI350kyUHVJf"
      },
      "outputs": [],
      "source": [
        "!mkdir OID\n",
        "!mkdir OID/Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlYPiYrBSUVQ"
      },
      "source": [
        "#python main.py downloader --classes <class names> --type_csv <train/test/validation/all> --limit <number of image from each class>\n",
        "\n",
        "## By adding --yoloLabelStyle to the command above, the output labels will be the yolo format, but if you don' add this switch, You have to change the format to the proper one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bdjRjS12HZ8N",
        "outputId": "2264e8d9-7c30-497c-d268-174365502a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [INFO] |  saving dataset configurations at ./OID/Dataset/config.json\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _       _    _  \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |     | |  | |    \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_    |  | | |   \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _|     | | | \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_       | |\n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|     |_|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Apple.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0my\n",
            "...145%, 0 MB, 25467 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into ./OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0my\n",
            "...0%, 3 MB, 44973 KB/s, 0 seconds passed\n",
            "...100%, 1138 MB, 34884 KB/s, 33 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into ./OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mApple\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 1078 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 300 images.\u001b[0m\n",
            "    [INFO] | Download of 300 images in train.\u001b[0m\n",
            "100% 300/300 [04:26<00:00,  1.12it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Apple of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Banana.\u001b[0m\n",
            "\n",
            "\u001b[95mBanana\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 723 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 300 images.\u001b[0m\n",
            "    [INFO] | Download of 300 images in train.\u001b[0m\n",
            "100% 300/300 [04:25<00:00,  1.13it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Banana of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "classes = 'Apple Banana'\n",
        "samples = 300\n",
        "\n",
        "!python /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/main.py downloader --classes {classes} --type_csv train --limit {samples} --yoloLabelStyle\n",
        "#!python /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/main.py downloader --classes {classes} --type_csv train --limit {samples} --yoloLabelStyle --multiclasses 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht7DCwFpTUwT"
      },
      "source": [
        "#Let’s visualize our Data\n",
        "\n",
        "##\n",
        "\n",
        "The ToolKit is useful also for visualize the downloaded images with the respective labels.\n",
        "\n",
        "   ##python3 main.py visualizer\n",
        "In this way the default Dataset folder will be pointed to search the images and labels automatically. To point another folder it's possible to use --Dataset optional argument.\n",
        "\n",
        "   ##python3 main.py visualizer --Dataset desired_folder\n",
        "Then the system will ask you which folder to visualize (train, validation or test) and the desired class. Hence with d (next), a (previous) and q (exit) you will be able to explore all the images. Follow the menu for all the other options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Vw2LuNKoTVWq",
        "outputId": "4ee1a3b5-8436-4488-ac2e-810cd25be9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [INFO] |  try to laod dataset configurations at /content/OID/Dataset/config.json\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _       _    _  \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |     | |  | |    \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_    |  | | |   \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _|     | | | \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_       | |\n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|     |_|\n",
            "\t\u001b[0m\n",
            "\u001b[92m \n",
            "            _    _ _                  _ _                  \n",
            "           | |  | (_)                | (_)                 \n",
            "           | |  | |_  ___ _   _  ____| |_ _____ ____  ____ \n",
            "            \\ \\/ /| |/___) | | |/ _  | | (___  ) _  )/ ___)\n",
            "             \\  / | |___ | |_| ( ( | | | |/ __( (/ /| |    \n",
            "              \\/  |_(___/ \\____|\\_||_|_|_(_____)____)_|    \n",
            "                                                                                                                                                                                                    \n",
            "        \u001b[0m\n",
            "Which folder do you want to visualize (train, test, validation)? <exit>\n",
            "> train\n",
            "Which class? <exit>\n",
            "- Apple\n",
            "- Banana\n",
            "\n",
            "\n",
            "> Apple\n",
            "\n",
            "--------------------------------------------------------\n",
            "INFO:\n",
            "        - Press 'd' to select next image\n",
            "        - Press 'a' to select previous image\n",
            "        - Press 'e' to select a new class\n",
            "        - Press 'w' to select a new folder\n",
            "        - Press 'q' to exit\n",
            "  You can resize the window if it's not optimal\n",
            "--------------------------------------------------------\n",
            "\n",
            "qt.qpa.xcb: could not connect to display \n",
            "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/usr/local/lib/python3.10/dist-packages/cv2/qt/plugins\" even though it was found.\n",
            "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
            "\n",
            "Available platform plugins are: xcb.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!python3 main.py visualizer   #In this way the default Dataset folder will be pointed to search the images and labels automatically.\n",
        "!python3 /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/main.py visualizer --Dataset /content/OID/Dataset  #To point another folder it's possible to use --Dataset optional argument."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J6sNg9PTRfL"
      },
      "source": [
        "#Let’s download the data to our PC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0Sii-wTSMXQs",
        "outputId": "e91b542d-991a-4531-f828-e27b50053f4b"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/data.zip  /content/OID/Dataset/train/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eal1fMLIhzb"
      },
      "source": [
        "# Converting the annotations to the YOLO format which is:\n",
        "\n",
        "## **name_of_the_class    left    top     right     bottom**\n",
        "\n",
        " (https://github.com/EscVM/OIDv4_ToolKit)\n",
        "\n",
        "but yolo requires this:\n",
        "\n",
        "## **Yolo format ===>  name_of_class  x  y  width  height**\n",
        "where\n",
        "\n",
        "**name_of_class**: Class name for the bounding boxes of the object\n",
        "\n",
        "**x**: The x coordinate of the centre of the rectangle\n",
        "\n",
        "**y**: The y coordinate of the centre of the rectangle\n",
        "\n",
        "**width**: width of the rectangle\n",
        "\n",
        "**height**: height of the rectangle.\n",
        "\n",
        "###\n",
        "Changing the open image annotation to YOLO annotation:\n",
        "The open image dataset annotation has to be changed into the YOLO format before it can be used in the YOLO model training.\n",
        "\n",
        "First, let's understand the math involved in annotation transformation.\n",
        "\n",
        "We have the coordinates of the top left corner of the called represented as (left, top) and right bottom corner as (right, bottom).\n",
        "\n",
        "we can find the width of the image by subtracting the left from right. and similarly height by subtracting the top from bottom.\n",
        "\n",
        "width = right-left\n",
        "\n",
        "height = bottom - top\n",
        "\n",
        "Now the centre of the rectangle will be the midpoint of width and the height. hence x and y can be calculated as:\n",
        "\n",
        "x = left + (width / 2)\n",
        "\n",
        "y = top + (height / 2)\n",
        "\n",
        "now we have all the coordinates required for the YOLO annotations i.e. x,y, width, height. we can use these for YOLO object detection.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krHqdqZ-Hf5f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "# Specify the directory containing the text files\n",
        "root_directory = '/content/OID/Dataset/train/'  # Update this path\n",
        "classes = ['Apple', 'Banana']\n",
        "for aclass in classes:\n",
        "    label_directory = os.path.join(root_directory, f'{aclass}/labels/')\n",
        "    image_directory = os.path.join(root_directory, f'{aclass}/images/')\n",
        "    image_size = []\n",
        "    for imagepath in glob.glob(os.path.join(image_directory, '*.jpg')):\n",
        "        # Open the image and read its size\n",
        "        #with open(imagepath, 'r') as image:\n",
        "          image = cv2.imread(imagepath)\n",
        "          image_size.append(image.shape)\n",
        "\n",
        "    # Iterate over all text files in the specified directory\n",
        "    for num,filepath in enumerate(glob.glob(os.path.join(label_directory, '*.txt'))):\n",
        "        image_h = image_size[num][0]\n",
        "        image_w = image_size[num][1]\n",
        "        # Open the file and read its content\n",
        "        with open(filepath, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        # Modify each line as needed\n",
        "        modified_lines = []\n",
        "        for line in lines:\n",
        "            words = line.split()\n",
        "            if words:\n",
        "                if words[0].lower() == 'apple':\n",
        "                    words[0] = '1'\n",
        "                elif words[0].lower() == 'banana':\n",
        "                    words[0] = '0'\n",
        "\n",
        "\n",
        "                # Convert coordinates from string to float\n",
        "                left = float(words[1])\n",
        "                top = float(words[2])\n",
        "                right = float(words[3])\n",
        "                bottom = float(words[4])\n",
        "\n",
        "                # Calculate width and height\n",
        "                width = right - left\n",
        "                height = bottom - top\n",
        "\n",
        "                # Calculate the center coordinates\n",
        "                x = left + (width / 2)\n",
        "                y = top + (height / 2)\n",
        "\n",
        "                # Normalizing the coordinates\n",
        "                x_norm = x / image_w\n",
        "                y_norm = y / image_h\n",
        "                width_norm = width / image_w\n",
        "                height_norm = height/image_h\n",
        "\n",
        "                # Update the words list with the new values\n",
        "                words[1] = str(x_norm)\n",
        "                words[2] = str(y_norm)\n",
        "                words[3] = str(width_norm)\n",
        "                words[4] = str(height_norm)\n",
        "\n",
        "            modified_lines.append(' '.join(words))\n",
        "\n",
        "        # Write the modified content back to the file\n",
        "        with open(filepath, 'w') as file:\n",
        "            file.write('\\n'.join(modified_lines))\n",
        "\n",
        "        print(f\"Processed file: {filepath}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnZxkrtISmGw"
      },
      "source": [
        "# Refrences\n",
        "https://sharmaji27.medium.com/easiest-way-to-download-data-from-the-open-image-dataset-553dccfb92d8\n",
        "\n",
        "https://g-vj.medium.com/custom-image-dataset-for-yolo-object-detection-using-open-image-dataset-41c128b9231b\n",
        "\n",
        "https://github.com/ultralytics/ultralytics\n",
        "\n",
        "https://github.com/monocongo/openimages\n",
        "\n",
        "https://www.basic.ai/blog-post/data-annotation-for-yolo-model-training-techniques-and-best-practices-1\n",
        "\n",
        "https://docs.ultralytics.com/tasks/detect/#predict\n",
        "\n",
        "https://github.com/EscVM/OIDv4_ToolKit\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
